{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolutional Layer 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Prevent overfitting\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 127, 127, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 64)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27265 (106.50 KB)\n",
      "Trainable params: 27265 (106.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256, 1)  # Grayscale images, hence 1 channel\n",
    "model = create_model(input_shape)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the preprocessed data\n",
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "X_val = np.load('X_val.npy')\n",
    "y_val = np.load('y_val.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 21s 2s/step - loss: 0.6457 - accuracy: 0.7425 - val_loss: 0.5662 - val_accuracy: 0.8452\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 16s 2s/step - loss: 0.4616 - accuracy: 0.8832 - val_loss: 0.4494 - val_accuracy: 0.8452\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 16s 1s/step - loss: 0.3653 - accuracy: 0.8832 - val_loss: 0.5016 - val_accuracy: 0.8452\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3854 - accuracy: 0.8832 - val_loss: 0.4448 - val_accuracy: 0.8452\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3807 - accuracy: 0.8832 - val_loss: 0.4461 - val_accuracy: 0.8452\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3892 - accuracy: 0.8832 - val_loss: 0.4620 - val_accuracy: 0.8452\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3695 - accuracy: 0.8832 - val_loss: 0.4483 - val_accuracy: 0.8452\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3652 - accuracy: 0.8832 - val_loss: 0.4611 - val_accuracy: 0.8452\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3691 - accuracy: 0.8832 - val_loss: 0.4491 - val_accuracy: 0.8452\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3545 - accuracy: 0.8832 - val_loss: 0.4601 - val_accuracy: 0.8452\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3669 - accuracy: 0.8832 - val_loss: 0.4628 - val_accuracy: 0.8452\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3615 - accuracy: 0.8832 - val_loss: 0.4523 - val_accuracy: 0.8452\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3669 - accuracy: 0.8832 - val_loss: 0.4597 - val_accuracy: 0.8452\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3635 - accuracy: 0.8832 - val_loss: 0.4552 - val_accuracy: 0.8452\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 15s 1s/step - loss: 0.3687 - accuracy: 0.8832 - val_loss: 0.4507 - val_accuracy: 0.8452\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,  #adjustable\n",
    "    batch_size=32,  # Typical batch size\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 84.52%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Aneurysm-Detection\\aneurysm\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save('aneurysm_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Model for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 279ms/step\n",
      "No Aneurysm\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "model = load_model('aneurysm_classifier.h5')\n",
    "\n",
    "# Predict on a new image\n",
    "def predict_image(model, image):\n",
    "    image_resized = cv2.resize(image, (256, 256)) / 255.0  # Resize and normalize\n",
    "    image_expanded = np.expand_dims(image_resized, axis=(0, -1))  # Expand dims for batch & channel\n",
    "    prediction = model.predict(image_expanded)\n",
    "    return \"Aneurysm Detected\" if prediction[0][0] > 0.5 else \"No Aneurysm\"\n",
    "\n",
    "# Example usage\n",
    "new_image = cv2.imread('test.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "print(predict_image(model, new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aneurysm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
